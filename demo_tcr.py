# -*- coding: utf-8 -*-
"""Pytorch_TCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xjf7j8f_zqmD4KV780KIFmWH6rNb-cQ1
"""

#pip install kornia

import torch
import numpy as np
import kornia
import torch.nn as nn

class TCR(nn.Module):
    def __init__(self):
        super(TCR, self).__init__()

#        self.device = torch.device("cuda:0")
#        self.Ds = torch.load(saved_model_path)
        self.ang = np.deg2rad(45.0)    # Change the degree of rotation as per the task in hand 
        self.ang_neg= -1*self.ang
        self.max_tx, self.max_ty =2.0, 2.0      # Change as per the task
        self.min_tx, self.min_ty = -2.0, -2.0      # Change as per the task



        self.max_z, self.min_z = 1.03, 0.97         # Change as per the task

        
    def forward(self, img):
        
        bs= img[0]
        W= img[2]
        H= img[3]
        tx = ((self.max_tx - self.min_tx)*torch.rand((bs, 1))  + self.min_tx)
        ty = ((self.max_ty -self. min_ty)*torch.rand((bs, 1))  + self.min_ty)


        r = ((self.ang - self.ang_neg)*torch.rand((bs, 1))  + self.ang_neg)
        z = ((self.max_z - self.min_z)*torch.rand((bs, 1))  + self.min_z)        
        
        hx = ((self.ang - self.ang_neg)*torch.rand((bs, 1))  + self.ang_neg)
        hy = ((self.ang - self.ang_neg)*torch.rand((bs, 1))  + self.ang_neg)
        
        # Transformation Matrix

        a = hx -r
        b = hy +r
        T12 = torch.div(z*torch.sin(a), torch.cos(hx))

        T13 = torch.div( W*torch.cos(hx) - W*z*torch.cos(a) +2*tx*z*torch.cos(a) - H*z*torch.sin(a) + 2*ty*z*torch.sin(a) ,  2*torch.cos(hx))

        T21 = torch.div(z*torch.sin(b), torch.cos(hy))

        T22 = torch.div(z*torch.cos(b), torch.cos(hy))

        T23 = torch.div( H*torch.cos(hy) - W*z*torch.cos(b) +2*ty*z*torch.cos(b) - W*z*torch.sin(b) + 2*tx*z*torch.sin(b) ,  2*torch.cos(hy))

        T=torch.zeros((bs,2,3))  #Combined for batch


        for i in range(bs):
            T[i]= torch.tensor([[T11[i], T12[i], T13[i]], [T21[i], T22[i], T23[i]]])   # Transformation Matrix for a batch
            
        Transformed_img = kornia.warp_affine(img, T, dsize=(W, H))    


        return loss
    
    
# The ground truth image (say y)
# y.shape is [bs, W, H]
# bs is the batch size
bs= 5 #assume
W,H= 1000,500 # assume
#Random Transformation

ang = np.deg2rad(1.0)    # Change the degree of rotation as per the task in hand 
ang_neg= -1*ang

max_tx, max_ty =2.0, 2.0      # Change as per the task
min_tx, min_ty = -2.0, -2.0      # Change as per the task

tx = ((max_tx - min_tx)*torch.rand((bs, 1))  + min_tx)
ty = ((max_ty - min_ty)*torch.rand((bs, 1))  + min_ty)


r = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)


max_z, min_z = 1.03, 0.97         # Change as per the task
z = ((max_z - min_z)*torch.rand((bs, 1))  + min_z)


hx = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)
hy = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)

# Transformation Matrix

a = hx -r
b = hy +r
T11 = torch.div(z*torch.cos(a), torch.cos(hx))

T12 = torch.div(z*torch.sin(a), torch.cos(hx))

T13 = torch.div( W*torch.cos(hx) - W*z*torch.cos(a) +2*tx*z*torch.cos(a) - H*z*torch.sin(a) + 2*ty*z*torch.sin(a) ,  2*torch.cos(hx))

T21 = torch.div(z*torch.sin(b), torch.cos(hy))

T22 = torch.div(z*torch.cos(b), torch.cos(hy))

T23 = torch.div( H*torch.cos(hy) - W*z*torch.cos(b) +2*ty*z*torch.cos(b) - W*z*torch.sin(b) + 2*tx*z*torch.sin(b) ,  2*torch.cos(hy))



T=torch.zeros((bs,2,3))


for i in range(bs):
  T[i]= torch.tensor([[T11[i], T12[i], T13[i]], [T21[i], T22[i], T23[i]]])

print(T.shape)   # [bs, 2, 3]

# We perform the transformations here, Please make sure the same transformations are made to the output and the ground truth images, to maintain consistency

#Transforming the ground truth image
y= torch.rand((bs,3,1000,500)) # Kindly change this accordning to the predicted output
Transformed_y = kornia.warp_affine(y, T, dsize=(W, H))

# This is where our model would be. The output of the model is also tranformed as follows:

#Transforming the predicted image
#output is the model's prediction
Transformed_op = kornia.warp_affine(output, T, dsize=(W, H))