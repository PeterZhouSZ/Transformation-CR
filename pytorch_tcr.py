# -*- coding: utf-8 -*-
"""Pytorch_TCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xjf7j8f_zqmD4KV780KIFmWH6rNb-cQ1
"""

pip install kornia

import torch
import numpy as np
import kornia

# The ground truth image (say y)
# y.shape is [bs, W, H]
# bs is the batch size
bs= 5 #assume
W,H= 1000,500 # assume
#Random Transformation

ang = np.deg2rad(1.0)    # Change the degree of rotation as per the task in hand 
ang_neg= -1*ang

max_tx, max_ty =2.0, 2.0      # Change as per the task
min_tx, min_ty = -2.0, -2.0      # Change as per the task

tx = ((max_tx - min_tx)*torch.rand((bs, 1))  + min_tx)
ty = ((max_ty - min_ty)*torch.rand((bs, 1))  + min_ty)


r = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)


max_z, min_z = 1.03, 0.97         # Change as per the task
z = ((max_z - min_z)*torch.rand((bs, 1))  + min_z)


hx = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)
hy = ((ang - ang_neg)*torch.rand((bs, 1))  + ang_neg)

# Transformation Matrix

a = hx -r
b = hy +r
T11 = torch.div(z*torch.cos(a), torch.cos(hx))

T12 = torch.div(z*torch.sin(a), torch.cos(hx))

T13 = torch.div( W*torch.cos(hx) - W*z*torch.cos(a) +2*tx*z*torch.cos(a) - H*z*torch.sin(a) + 2*ty*z*torch.sin(a) ,  2*torch.cos(hx))

T21 = torch.div(z*torch.sin(b), torch.cos(hy))

T22 = torch.div(z*torch.cos(b), torch.cos(hy))

T23 = torch.div( H*torch.cos(hy) - W*z*torch.cos(b) +2*ty*z*torch.cos(b) - W*z*torch.sin(b) + 2*tx*z*torch.sin(b) ,  2*torch.cos(hy))



T=torch.zeros((bs,2,3))


for i in range(bs):
  T[i]= torch.tensor([[T11[i], T12[i], T13[i]], [T21[i], T22[i], T23[i]]])

print(T.shape)   # [bs, 2, 3]

# We perform the transformations here, Please make sure the same transformations are made to the output and the ground truth images, to maintain consistency

#Transforming the ground truth image
y= torch.rand((bs,3,1000,500)) # Kindly change this accordning to the predicted output
Transformed_y = kornia.warp_affine(y, T, dsize=(W, H))

# This is where our model would be. The output of the model is also tranformed as follows:

#Transforming the predicted image
#output is the model's prediction
Transformed_op = kornia.warp_affine(output, T, dsize=(W, H))